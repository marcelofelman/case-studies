# C칩mo mejorar la clasificaci칩n de im치genes con Deep Learning

>**TL;DR** sigue algunas de estas ideas para mejorar tus modelos de clasificaci칩n de im치genes.

Existen t칠cnicas y algoritmos de Deep Learning para clasificaci칩n de im치genes que permiten alcanzar niveles de precisi칩n *aceptables* sin que siquiera entremos en detalle de c칩mo funcionan, qu칠 par치metros reciben o detalles m치s finos de implementaci칩n. En este post recorreremos distintas formas pr치cticas de mejorar nuestros modelos cuando deseemos llevar nuestra performance al siguiente nivel.

## Contexto

Estos aprendizajes los hemos adquirido trabajando con uno de nuestros clientes cuyo objetivo es crear una red neuronal que permita clasificar el estado fenol칩gico de una flor a partir de una im치gen de la misma.

Un estado fenol칩gico de una planta indica el nivel de madurez de la misma seg칰n criterios que afectan su medio ambiente. Esto es particularmente interesante para agricultores o productores, ya que pueden determinar datos importantes tales como cu치nto falta para cultivar, si hay enfermedades o si hay anomal칤as en los frutos.

![Estados fenol칩gicos de una flor](https://github.com/marcelofelman/case-studies/blob/master/images/1-estados-fenologicos.png?raw=true)

*Imagen cortes칤a de Wikipedia. [Wikipedia](https://wikipedia.com)*

El ejemplo anterior se trata de una clasificaci칩n de m칰ltiples clases. Algunas resultan m치s f치ciles de distinguir, mientras que otras a simple vista parecen similares e inclusive dif칤ciles de distinguir para un experto del dominio.

Si bien basaremos este ejemplo sobre estados fenol칩gicos, ten en cuenta que estas pr치cticas aplican a cualquier tipo de clasficicaci칩n de im치genes.

## Tecnolog칤as

Para este proyecto contamos con:

- Un conjunto de datos de aproximadamente 1000 im치genes por cada categor칤a, con 7 categor칤as.
- Especialistas del dominio de estados fenol칩gicos.

Las tecnolog칤as utilizadas fueron:

- [Data Science Virtual Machine](https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/provision-vm)
- [Jupyter Notebooks](http://jupyter.org)
- [Anaconda Python](https://anaconda.org/anaconda/python)
- [Keras](https://keras.io)
- [CNTK](https://www.microsoft.com/en-us/cognitive-toolkit/)
- [TensorFlow](http://tensorflow.org)
- [Node.js](https://nodejs.org/en/)

## Ideas sobre c칩mo mejorar

En un contexto inicial, se lograba entre un 70 y 80% de precisi칩n. Estas son algunas de las ideas que tuvimos para mejorar aquella precisi칩n:

- [Probar distintos algoritmos](#probar-distintos-algoritmos)
- [Mejorar los datasets de entrenamiento](#mejorar-los-datasets-de-entrenamiento)
- [Re-pensar las clases](#re-pensar-las-clases)
- [Crear un meta-modelo](#crear-un-meta-modelo)

## Probar distintos algoritmos

Una de las maneras m치s intuitivas de tratar de mejorar es probando con nuevos algoritmos, redes o t칠cnicas. 

Inicialmente, el modelo estaba basado en una red neuronal convolucional (CNN o ConvNet) creada con Keras. M치s info [aqu칤](https://keras.io/layers/convolutional/). Una de las grandes ventajas de utilizar Keras, es que nos abstraemos enormemente de la implementaci칩n de los algoritmos. Adem치s, podemos elegir entre Tensorflow, CNTK o Theano como motor de nuestras redes.

Si no conoces Keras y est치s empezando con Deep Learning, es altamente recomendado. La sintaxis le facilita muchas tareas al desarrollador. S칩lo un ejemplo:

```python
# Compile model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
```

Alguno de los algoritmos, redes o t칠cnicas que probamos:

### One-shot learning

- [One-shot learning con Keras](https://sorenbouma.github.io/blog/oneshot/)
- [One-shot learning con Theano](https://github.com/tristandeleu/ntm-one-shot)
- [One-shot learning con Tensorflow](https://github.com/AntreasAntoniou/MatchingNetworks)

One-shot learning es una t칠cnica que apunta a crear modelos a partir de conjuntos de datos mucho m치s reducidos que los t칤picos. A grandes rasgos, la intenci칩n del algoritmo es emular la extracci칩n de caracter칤sticas como hacen los seres humanos, los cuales, por ejemplo, no necesitan ver millones de im치genes de un perro para reconocer que se trata de uno de ellos.

Notar치s que los links anteriores tienen un nivel considerable de complejidad. En nuestro caso, logramos implementar varios de estos modelos sin llegar al detalle fino sobre el comportamiento de cada parte. No es lo m치s recomendable, pero si lo m치s pr치ctico.

### AlexNet

- [AlexNet con Keras](https://github.com/duggalrahul/AlexNet-Experiments-Keras)

AlexNet es una red neuronal convolucional que ha recibido m칰ltiples premios a nivel internacional por su performance en clasificaci칩n de im치genes. El art칤culo original puede encontrarse en [este link](http://vision.stanford.edu/teaching/cs231b_spring1415/slides/alexnet_tugce_kyunghee.pdf).

AlexNet es otro de esos casos en los que podemos hacer pruebas sin bajar al detalle fino detr치s de la red, y tomarlo como una caja negra.

Desafortunadamente para nuestros casos, nuestros niveles de precisi칩n no mejoraron. En un aspecto m치s positivo, nuestros tiempos de entrenamiento se vieron reducidos en un 50%.

>**Tip pr치ctico** Intenta distintas redes, algoritmos o t칠cnicas a칰n si tengamos que tratarlos como "cajas negras".

## Mejorar los datasets de entrenamiento

Algunas de las categor칤as resultaban dif칤ciles de discernir inclusive para los expertos del dominio. Una buena idea es consultar con varios especialistas cu치l es su *input* sobre una determinada imagen.

Para ello, decidimos construir una aplicaci칩n web liviana que permitiera la clasificaci칩n de im치genes. El comportamiento es muy simple: muestra una imagen y permite elegir una categor칤a.

![Aplicaci칩n de clasificaci칩n de im치genes](https://github.com/marcelofelman/case-studies/blob/master/images/2-app-clasificacion.png?raw=true)

En nuestro caso optamos por crearla para satisfacer una necesidad bien particular, pero ten presente que existen much칤simas herramientas para anotar o clasificar im치genes.

[Wikipedia ofrece una lista de m치s de una docena de herramientas.](https://en.wikipedia.org/wiki/List_of_manual_image_annotation_tools)

Recuerda que los conjuntos de entrenamientos son la parte m치s importante de tu aplicaci칩n, un error puede ser muy costos en la precisi칩n del modelo.

## Re-pensar las clases

De todos los puntos que -para nuestro caso- trajeron un mayor grado de precisi칩n, volver a pensar las clases fue el que mayor impacto tuvo.

쯇or qu칠 7 categor칤as y no menos? 쯊iene alg칰n sentido desde el punto de vista del negocio?

Esas dos preguntas permitieron re-pensar nuestro enfoque de manera completamente distinta. Para ello, en resumidas cuentas, empleamos un algoritmo de entrenamiento no supervisado llamado *k-means* que tiene por objetivo encontrar relaciones o grupos entre los datos.

Este algoritmo nos dio como resultado que exist칤an idealmente 5 clases en lugar de 7. De esta forma, pudimos re-catalogar nuestra informaci칩n para lograr mejor precisi칩n. Recuerda: ante menos clases, mayor probabilidad de acertar correctamente.

Al ser este caso tan importante, creamos un documento independiente a este. Puedes ver m치s informaci칩n [aqu칤](completar con el link de clustering).

## Crear un meta-modelo

Un meta-modelo es b치sicamente un modelo constitu칤do por distintos modelos. Esto tiene una gran ventaja, que es que pudimos crear una red neuronal "generalista" que es relativamente buena en identificar las clases. Por otra parte, podemos crear otras redes neuronales que son muy buenas en "desempatar" o en clasificar dos estados dif칤ciles de entender.

Un ejemplo: si observas la figura c y d del ejemplo de arriba, notar치s que son im치genes muy similares. Nuestro modelo tal vez pueda ser muy bueno en detectar las diferencias entre a y d, pero no tanto para c y d. Entonces, creamos otra red que sea muy buena clasificando entre esos dos ejemplos.

A nivel pseudo-c칩digo, funciona de la siguiente forma:

-> Nueva imagen -> Consultar con la red neuronal general

    -> Si la precisi칩n es baja para un estado "dif칤cil"

        -> Consultar con la red experta en desempatar estados dif칤ciles
        
    -> Sino, me quedo con el resultado

Esta 칰ltima parte no tiene tanto que ver con l칩gica de ciencia de datos, sino m치s bien se trata de un *hack* de programadores 游.

## Resultados y conclusiones

Tras estos cambios, nuestro modelo logr칩 una mejor precisi칩n total para la clasificaci칩n de im치genes. Dada la sensibildad de los casos de nuestro cliente, no podemos compartir los n칰meros exactos.

Puntualmente, cada secci칩n result칩 de distintas maneras:

- One-shot learning: es complejo de implementar y la performance result칩 similar a una CNN.
- AlexNet: la performance resulto similar a una CNN, pero los tiempos de entrenamiento se redujeron.
- Clustering: pieza important칤sima que permiti칩, sin cambios en el c칩digo, enfocar el problema de otra forma.
- Revisi칩n de etiquetas: siempre ayuda refinar el conjunto de datos
- Meta-modelo: aumenta los costos y la complejidad favoreciendo la performance y precisi칩n.

El aprendizaje m치s importante que obtuvimos en este escenario es que, inclusive en Deep Learning, *no todos los problemas se resuelven con redes m치s complejas, m치s par치metros, algoritmos m치s sofisticados o m치s GPU*. A veces, todo lo que necesitas es dar un paso atr치s y ver tus problemas desde otra 칩ptica.

## Equipo

Jorge Cupi - [Twitter](https://twitter.com/jorgecupi) - [GitHub](https://github.com/jorgecupi)

Marcelo Felman - [Twitter](https://twitter.com/mfelman) - [GitHub](https://github.com/marcelofelman)